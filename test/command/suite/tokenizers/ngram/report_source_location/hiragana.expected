tokenize   'TokenNgram("report_source_location", true)'   "あいうえお"   'NormalizerNFKC100("report_source_offset", true)'
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "あい",
      "position": 0,
      "force_prefix": false,
      "source_offset": 0,
      "source_length": 6,
      "source_first_character_length": 3
    },
    {
      "value": "いう",
      "position": 1,
      "force_prefix": false,
      "source_offset": 3,
      "source_length": 6,
      "source_first_character_length": 3
    },
    {
      "value": "うえ",
      "position": 2,
      "force_prefix": false,
      "source_offset": 6,
      "source_length": 6,
      "source_first_character_length": 3
    },
    {
      "value": "えお",
      "position": 3,
      "force_prefix": false,
      "source_offset": 9,
      "source_length": 6,
      "source_first_character_length": 3
    },
    {
      "value": "お",
      "position": 4,
      "force_prefix": false,
      "source_offset": 12,
      "source_length": 3,
      "source_first_character_length": 3
    }
  ]
]
