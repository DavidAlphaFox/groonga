tokenize   'TokenMecab("chunked_tokenize", true, "chunk_size_threshold", 30)'   '日本のエンジンとエンジン'
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "日本",
      "position": 0,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "の",
      "position": 1,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "エンジン",
      "position": 2,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "と",
      "position": 3,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "エン",
      "position": 4,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "ジン",
      "position": 5,
      "force_prefix": false,
      "force_prefix_search": false
    }
  ]
]
