Execution example::

  tokenize 'TokenMecab("target_class", "-名詞/非自立", "target_class", "-名詞/接尾/人名", "target_class", "名詞", "include_reading", true)' '彼の名前は山田さんのはずです。'
  # [
  #   [
  #     0,
  #     1546841272.495518,
  #     0.0003752708435058594
  #   ],
  #   [
  #     {
  #       "value": "彼",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false,
  #       "metadata": {
  #         "reading": "カレ"
  #       }
  #     },
  #     {
  #       "value": "名前",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false,
  #       "metadata": {
  #         "reading": "ナマエ"
  #       }
  #     },
  #     {
  #       "value": "山田",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false,
  #       "metadata": {
  #         "reading": "ヤマダ"
  #       }
  #     }
  #   ]
  # ]
  normalize   'NormalizerNFKC100("unify_to_romaji", true)'   "カレ"   WITH_TYPES
  # [
  #   [
  #     0,
  #     1546841303.223331,
  #     0.000186920166015625
  #   ],
  #   {
  #     "normalized": "kare",
  #     "types": [
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha"
  #     ],
  #     "checks": [
  #     ]
  #   }
  # ]
  normalize   'NormalizerNFKC100("unify_to_romaji", true)'   "ナマエ"   WITH_TYPES
  # [
  #   [
  #     0,
  #     1546841329.839442,
  #     0.0001835823059082031
  #   ],
  #   {
  #     "normalized": "namae",
  #     "types": [
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha"
  #     ],
  #     "checks": [
  #     ]
  #   }
  # ]
  normalize   'NormalizerNFKC100("unify_to_romaji", true)'   "ヤマダ"   WITH_TYPES
  # [
  #   [
  #     0,
  #     1546841358.479471,
  #     0.0001850128173828125
  #   ],
  #   {
  #     "normalized": "yamada",
  #     "types": [
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha",
  #       "alpha"
  #     ],
  #     "checks": [
  #     ]
  #   }
  # ]
